{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a65989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import PIL \n",
    "from PIL import Image \n",
    "import sklearn \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import cv2\n",
    "import fcswrite\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006dae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single FOV, all in one timepoint/folder (Standard export format)\n",
    "\n",
    "\n",
    "\n",
    "def process_grayscale_images_by_well(folder_path):\n",
    "    expected_channels = [\"w1\", \"w2\", \"w3\", \"w4\"]\n",
    "    well_pattern = re.compile(r'([A-F][0-9]{2})')\n",
    "    channel_pattern = re.compile(r'(w[1-4])')\n",
    "\n",
    "    images_by_well = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.startswith(\"._\") or not filename.endswith(\".TIF\"):\n",
    "            continue\n",
    "\n",
    "        well_match = well_pattern.search(filename)\n",
    "        channel_match = channel_pattern.search(filename)\n",
    "\n",
    "        if well_match and channel_match:\n",
    "            well = well_match.group(1)\n",
    "            channel = channel_match.group(1)\n",
    "\n",
    "            images_by_well.setdefault(well, {})[channel] = os.path.join(folder_path, filename)\n",
    "\n",
    "    for well, channel_files in images_by_well.items():\n",
    "        print(f\"Processing well: {well}\")\n",
    "        data = {\"X\": [], \"Y\": []}\n",
    "        all_positions = []\n",
    "        \n",
    "        for channel in expected_channels:\n",
    "            if channel in channel_files:\n",
    "                image = Image.open(channel_files[channel])\n",
    "                image_array = np.array(image)\n",
    "\n",
    "                # #BACKGROUND SUBTRACTION\n",
    "                # percentile_subtract = np.percentile(image_array, 30)\n",
    "                # image_array = np.clip(image_array - percentile_subtract, a_min=0, a_max=None)\n",
    "                # #BACKGROUND SUBTRACTION\n",
    "\n",
    "                height, width = image_array.shape\n",
    "\n",
    "                if len(all_positions) == 0:\n",
    "                    positions = np.indices((height, width)).reshape(2, -1).T\n",
    "                    all_positions = positions\n",
    "                    data[\"X\"], data[\"Y\"] = positions.T\n",
    "\n",
    "                data[channel] = image_array.flatten()\n",
    "            else:\n",
    "                data[channel] = np.zeros(len(all_positions))\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"total_intensity\"] = df[expected_channels].sum(axis=1)\n",
    "       \n",
    "\n",
    "        for channel in expected_channels:\n",
    "            df[f\"p_{channel}\"] = np.where(df[\"total_intensity\"] > 0,\n",
    "                                          df[channel] / df[\"total_intensity\"], 0)\n",
    "\n",
    "        #Change to fit your nomenclature \n",
    "        output_fcs_path = os.path.join(folder_path, f\"d6_02_{well}.fcs\")\n",
    "        parameter_names = [\"X\", \"Y\", \"texas red\", \"w2\", 'w3', 'w4', \"total_intensity\"]\n",
    "        data_matrix = df[parameter_names].to_numpy(dtype=np.float64)\n",
    "        fcswrite.write_fcs(output_fcs_path, parameter_names, data_matrix)\n",
    "\n",
    "        #Use below to export to CSV to troubleshoot\n",
    "        # df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "        print(f\"Saved FCS for well {well} to {output_fcs_path}\")\n",
    "\n",
    "# Run on the full image folder, change \n",
    "image_folder = \"/Volumes/Trevor/Melina 2D3D/MX Format/Melina pilot 2D pool d6 02_Plate_52522/TimePoint_1\"\n",
    "process_grayscale_images_by_well(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59690f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder of folders\n",
    "\n",
    "\n",
    "def process_all_plates(root_folder):\n",
    "    expected_channels = [\"w1\", \"w2\"]\n",
    "    well_pattern = re.compile(r'([A-F][0-9]{2})')\n",
    "    channel_pattern = re.compile(r'(w[1-4])')\n",
    "\n",
    "    output_base = \"/Volumes/Elements/Dox NH2 July 2025/Per Well Median Background Subtraction\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    for subfolder in os.listdir(root_folder):\n",
    "        subfolder_path = os.path.join(root_folder, subfolder)\n",
    "        timepoint_path = os.path.join(subfolder_path, \"TimePoint_1\")\n",
    "\n",
    "        if not os.path.isdir(timepoint_path):\n",
    "            continue\n",
    "\n",
    "        # Extract prefix for file naming (e.g., d0p1)\n",
    "        prefix_match = re.search(r'D(\\d+)\\s+P(\\d+)', subfolder, re.IGNORECASE)\n",
    "        if not prefix_match:\n",
    "            print(f\"Skipping {subfolder}, couldn't parse day/plate info.\")\n",
    "            continue\n",
    "        prefix = f\"d{prefix_match.group(1).lower()}p{prefix_match.group(2).lower()}\"\n",
    "\n",
    "        images_by_well = {}\n",
    "        for filename in os.listdir(timepoint_path):\n",
    "            if filename.startswith(\"._\") or not filename.endswith(\".TIF\"):\n",
    "                continue\n",
    "\n",
    "            well_match = well_pattern.search(filename)\n",
    "            channel_match = channel_pattern.search(filename)\n",
    "\n",
    "            if well_match and channel_match:\n",
    "                well = well_match.group(1)\n",
    "                channel = channel_match.group(1)\n",
    "                images_by_well.setdefault(well, {})[channel] = os.path.join(timepoint_path, filename)\n",
    "\n",
    "        for well, channel_files in images_by_well.items():\n",
    "            print(f\"Processing well: {well} from {subfolder}\")\n",
    "            data = {\"X\": [], \"Y\": []}\n",
    "            all_positions = []\n",
    "\n",
    "            for channel in expected_channels:\n",
    "                if channel in channel_files:\n",
    "                    image = Image.open(channel_files[channel])\n",
    "                    image_array = np.array(image)\n",
    "\n",
    "                    #Background Subtraction\n",
    "                    percentile_subtract = np.percentile(image_array, 50)\n",
    "                    image_array = np.clip(image_array - percentile_subtract, a_min=0, a_max=None)\n",
    "                    #Background Subtraction\n",
    "            \n",
    "                    height, width = image_array.shape\n",
    "\n",
    "                    if len(all_positions) == 0:\n",
    "                        positions = np.indices((height, width)).reshape(2, -1).T\n",
    "                        all_positions = positions\n",
    "                        data[\"X\"], data[\"Y\"] = positions.T\n",
    "\n",
    "                    data[channel] = image_array.flatten()\n",
    "                else:\n",
    "                    data[channel] = np.zeros(len(all_positions))\n",
    "\n",
    "            df = pd.DataFrame(data)\n",
    "            df[\"total_intensity\"] = df[expected_channels].sum(axis=1)\n",
    "            df[\"r_y\"] = df['w1']/df[\"w2\"]\n",
    "            df[\"r_g\"] = df['w1']/df[\"w3\"]\n",
    "            df[\"r_b\"] = df['w1']/df[\"w4\"]\n",
    "            df[\"y_g\"] = df['w2']/df[\"w3\"]\n",
    "            df[\"y_b\"] = df['w2']/df[\"w4\"]\n",
    "            df[\"g_b\"] = df['w3']/df[\"w4\"]\n",
    "\n",
    "\n",
    "\n",
    "            for channel in expected_channels:\n",
    "                df[f\"p_{channel}\"] = np.where(df[\"total_intensity\"] > 0,\n",
    "                                              df[channel] / df[\"total_intensity\"], 0)\n",
    "\n",
    "            parameter_names = [\"X\", \"Y\", \"texas_red\", \"yfp\", \"fitc\", \"cfp\", \"total_intensity\", \"r_y\", \"r_g\", \"r_b\", \"y_g\", \"y_b\", \"g_b\"]\n",
    "            data_matrix = df[[\"X\", \"Y\", \"w1\", \"w2\", \"w3\", \"w4\", \"total_intensity\", \"r_y\", \"r_g\", \"r_b\", \"y_g\", \"y_b\", \"g_b\"]].to_numpy(dtype=np.float64)\n",
    "\n",
    "            output_fcs_path = os.path.join(output_base, f\"{prefix}_{well}.fcs\")\n",
    "            write_fcs(output_fcs_path, parameter_names, data_matrix)\n",
    "            print(f\"Saved: {output_fcs_path}\")\n",
    "\n",
    "# Usage\n",
    "root_folder = \"/Volumes/Elements/Dox NH2 July 2025/Raw Data\"\n",
    "process_all_plates(root_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
